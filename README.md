# Rapid Prototyping of Human-Robot Interactions via Verbal Authoring

Contributors (in no particular order): Mayank Mali, Linda Wu, Ali Zaidi

This paper is a draft submission for the SIGCHI conference. Created for the CS 639 class Undergrad Research in HCI at UWisconsin-Madison HCI Lab during Spring 2018.

Keywords: Authoring Systems; visual programming; verbal authoring; speech-based interfaces; human-robot interaction; robot-programming

## Abstract 

Robotic products are becoming increasingly commonplace. Introducing these products into day-to-day settings involves an interaction designer to “author” the robot’s behavior. 
Traditionally, the designer authors interactions using connected visual nodes that model behaviors. Visual authoring enables designers with little programming experience to design robot
behaviors but still requires the designer to learn the environment’s conventions and the setup of the environment-robot system, which can become barriers to rapid prototyping and design.
In this paper, we present an authoring approach that aims to remove these barriers and provides the designer with the ability to create and implement robot behaviors using natural
spoken language. We implemented our verbal authoring tool and evaluated the effectiveness of and user experience with the tool by comparing it against a popular visual authoring system
called Choregraphe. Based on data from 24 participants, our findings show our verbal-authoring approach to improve usability and task performance in measures of task-completion rate 
and task time, without increasing user task load compared to a state-of-the-art graphical approach.
